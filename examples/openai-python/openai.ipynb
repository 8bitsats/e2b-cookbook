{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Code Interpreting with OpenAi models\n",
        "This example uses the E2B's [Code Interpreter](https://github.com/e2b-dev/code-interpreter) as a tool for OpenAI's model. You can choose from models with function-calling support, such as o1 or o3-mini.\n",
        "We let the LLM write the code to train a machine learning model on a dataset from Kaggle. We use the E2B Code Interpreter SDK for running the LLM-generated code tasks in a secure and isolated cloud environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5kS-plOSMWnS",
        "outputId": "40488472-d554-4aea-fb75-5699c2bdd725"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: openai in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (1.54.5)\n",
            "Requirement already satisfied: e2b_code_interpreter==1.0.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (1.0.0)\n",
            "Requirement already satisfied: attrs>=21.3.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from e2b_code_interpreter==1.0.0) (23.2.0)\n",
            "Requirement already satisfied: e2b<2.0.0,>=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from e2b_code_interpreter==1.0.0) (1.0.1)\n",
            "Requirement already satisfied: httpx<0.28.0,>=0.20.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from e2b_code_interpreter==1.0.0) (0.27.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from openai) (4.6.2.post1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from openai) (1.8.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from openai) (0.4.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from openai) (2.9.1)\n",
            "Requirement already satisfied: sniffio in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from openai) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: httpcore<2.0.0,>=1.0.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from e2b<2.0.0,>=1.0.0->e2b_code_interpreter==1.0.0) (1.0.5)\n",
            "Requirement already satisfied: packaging<25.0,>=24.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from e2b<2.0.0,>=1.0.0->e2b_code_interpreter==1.0.0) (24.1)\n",
            "Requirement already satisfied: protobuf<6.0.0,>=3.20.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from e2b<2.0.0,>=1.0.0->e2b_code_interpreter==1.0.0) (4.24.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from e2b<2.0.0,>=1.0.0->e2b_code_interpreter==1.0.0) (2.8.2)\n",
            "Requirement already satisfied: certifi in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from httpx<0.28.0,>=0.20.0->e2b_code_interpreter==1.0.0) (2024.8.30)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from httpcore<2.0.0,>=1.0.5->e2b<2.0.0,>=1.0.0->e2b_code_interpreter==1.0.0) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (2.23.3)\n",
            "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from python-dateutil>=2.8.2->e2b<2.0.0,>=1.0.0->e2b_code_interpreter==1.0.0) (1.16.0)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install openai e2b_code_interpreter==1.0.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "locUMi_ANJek"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from openai import OpenAI\n",
        "import json\n",
        "from e2b_code_interpreter import Sandbox\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
        "E2B_API_KEY = os.getenv(\"E2B_API_KEY\")\n",
        "\n",
        "SYSTEM_PROMPT = \"\"\"\n",
        "## your job & context\n",
        "you are a python data scientist. you are given tasks to complete and you run python code to solve them.\n",
        "\n",
        "Information about the temperature dataset:\n",
        "- It's in the `/home/user/city_temperature.csv` file\n",
        "- The CSV file is using `,` as the delimiter\n",
        "- It has following columns (examples included):\n",
        "  - `Region`: \"North America\", \"Europe\"\n",
        "  - `Country`: \"Iceland\"\n",
        "  - `State`: for example \"Texas\" but can also be null\n",
        "  - `City`: \"Prague\"\n",
        "  - `Month`: \"June\"\n",
        "  - `Day`: 1-31\n",
        "  - `Year`: 2002\n",
        "  - `AvgTemperature`: temperature in Celsius, for example 24\n",
        "\n",
        "- the python code runs in jupyter notebook.\n",
        "- every time you call `execute_python` tool, the python code is executed in a separate cell. it's okay to multiple calls to `execute_python`.\n",
        "- display visualizations using matplotlib or any other visualization library directly in the notebook. don't worry about saving the visualizations to a file.\n",
        "- you have access to the internet and can make api requests.\n",
        "- you also have access to the filesystem and can read/write files.\n",
        "- you can install any pip package (if it exists) if you need to but the usual packages for data analysis are already preinstalled.\n",
        "- you can run any python code you want, everything is running in a secure sandbox environment.\n",
        "\"\"\"\n",
        "\n",
        "tools = [\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"execute_python\",\n",
        "            \"description\": \"Execute python code in a Jupyter notebook cell and returns any result, stdout, stderr, display_data, and error.\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"code\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"The python code to execute in a single cell.\"\n",
        "                    }\n",
        "                },\n",
        "                \"required\": [\"code\"]\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "k_bbA6P7NGOQ"
      },
      "outputs": [],
      "source": [
        "def code_interpret(code_interpreter, code):\n",
        "    print(\"Running code interpreter...\")\n",
        "    \n",
        "    exec = code_interpreter.run_code(\n",
        "        code,\n",
        "        on_stderr=lambda stderr: print(\"[Code Interpreter]\", stderr),\n",
        "        on_stdout=lambda stdout: print(\"[Code Interpreter]\", stdout)\n",
        "    )\n",
        "    \n",
        "    if exec.error:\n",
        "        print(\"[Code Interpreter ERROR]\", exec.error)\n",
        "        raise Exception(exec.error.value)\n",
        "        \n",
        "    return exec.results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "_1WPD2mAMjT2"
      },
      "outputs": [],
      "source": [
        "client = OpenAI(api_key=OPENAI_API_KEY)\n",
        "\n",
        "def process_tool_call(code_interpreter, tool_call):\n",
        "    if tool_call.function.name == \"execute_python\":\n",
        "        code = json.loads(tool_call.function.arguments)[\"code\"]\n",
        "        return code_interpret(code_interpreter, code)\n",
        "    return []\n",
        "\n",
        "def chat_with_llm(code_interpreter, user_message):\n",
        "    print(f\"\\n{'='*50}\\nUser Message: {user_message}\\n{'='*50}\")\n",
        "    \n",
        "    print('Waiting for the LLM to respond...')\n",
        "    completion = client.chat.completions.create(\n",
        "        model=\"o3\", #Choose different model by uncommenting\n",
        "        # model=\"o1\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
        "            {\"role\": \"user\", \"content\": user_message}\n",
        "        ],\n",
        "        tools=tools,\n",
        "        tool_choice=\"auto\"\n",
        "    )\n",
        "    \n",
        "    message = completion.choices[0].message\n",
        "    print('\\nInitial Response:', message)\n",
        "    \n",
        "    if message.tool_calls:\n",
        "        tool_call = message.tool_calls[0]\n",
        "        print(f\"\\nTool Used: {tool_call.function.name}\\nTool Input: {tool_call.function.arguments}\")\n",
        "        \n",
        "        code_interpreter_results = process_tool_call(code_interpreter, tool_call)\n",
        "        print(f\"Tool Result: {code_interpreter_results}\")\n",
        "        return code_interpreter_results\n",
        "    \n",
        "    raise Exception('Tool calls not found in message content.')\n",
        "\n",
        "\n",
        "def upload_dataset(code_interpreter):\n",
        "    print('Uploading dataset to Code Interpreter sandbox...')\n",
        "    dataset_path = './city_temperature.csv'\n",
        "    \n",
        "    if not os.path.exists(dataset_path):\n",
        "        raise Exception('Dataset file not found')\n",
        "    \n",
        "    with open(dataset_path, 'rb') as f:\n",
        "        file_buffer = f.read()\n",
        "    \n",
        "    try:\n",
        "        remote_path = code_interpreter.files.write('city_temperature.csv', file_buffer)\n",
        "        if not remote_path:\n",
        "            raise Exception('Failed to upload dataset')\n",
        "        print('Uploaded at', remote_path)\n",
        "        return remote_path\n",
        "    except Exception as error:\n",
        "        print('Error during file upload:', error)\n",
        "        raise error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "e2p2w9UqOX3L",
        "outputId": "45d46c4d-1c0a-4f14-8575-73459ff98816"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Uploading dataset to Code Interpreter sandbox...\n",
            "Uploaded at EntryInfo(name='city_temperature.csv', type='file', path='/home/user/city_temperature.csv')\n",
            "Remote path of the uploaded dataset: EntryInfo(name='city_temperature.csv', type='file', path='/home/user/city_temperature.csv')\n",
            "\n",
            "==================================================\n",
            "User Message: Analyze the temperature data for the top 5 hottest cities globally. Create a visualization showing their average temperatures over the years.\n",
            "==================================================\n",
            "Waiting for the LLM to respond...\n",
            "\n",
            "Initial Response: ChatCompletionMessage(content=None, refusal=None, role='assistant', audio=None, function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_OTCrG066LQJYJ8vBrYkmuPaJ', function=Function(arguments='{\"code\":\"import pandas as pd\\\\nimport matplotlib.pyplot as plt\\\\nimport seaborn as sns\\\\n\\\\n# 1) Read the data\\\\nfilepath = \\'/home/user/city_temperature.csv\\'\\\\ndf = pd.read_csv(filepath)\\\\n\\\\n# 2) Convert the AvgTemperature column to numeric if needed\\\\n#   (assuming it\\'s already numeric in Celsius as stated, but just in case)\\\\ndf[\\'AvgTemperature\\'] = pd.to_numeric(df[\\'AvgTemperature\\'], errors=\\'coerce\\')\\\\n\\\\n# Make sure no invalid entries\\\\ndf = df.dropna(subset=[\\'AvgTemperature\\'])\\\\n\\\\n# 3) Find top 5 hottest cities by overall average temperature\\\\ncity_avg_temps = df.groupby(\\'City\\', as_index=False)[\\'AvgTemperature\\'].mean()\\\\ncity_avg_temps_sorted = city_avg_temps.sort_values(\\'AvgTemperature\\', ascending=False)\\\\ntop_5_cities = city_avg_temps_sorted.head(5)[\\'City\\'].tolist()\\\\n\\\\n# 4) Filter dataframe to include only top 5 cities\\\\nfiltered_df = df[df[\\'City\\'].isin(top_5_cities)]\\\\n\\\\n# 5) Group by city and year to compute average temperature\\\\nyearly_mean = filtered_df.groupby([\\'City\\', \\'Year\\'], as_index=False)[\\'AvgTemperature\\'].mean()\\\\n\\\\n# 6) Create a line plot using seaborn or matplotlib\\\\nplt.figure(figsize=(10,6))\\\\nsns.lineplot(data=yearly_mean, x=\\'Year\\', y=\\'AvgTemperature\\', hue=\\'City\\', marker=\\'o\\')\\\\nplt.title(\\'Yearly Average Temperatures for Top 5 Hottest Cities\\')\\\\nplt.xlabel(\\'Year\\')\\\\nplt.ylabel(\\'Average Temperature (C)\\')\\\\nplt.legend(title=\\'City\\')\\\\nplt.tight_layout()\\\\nplt.show()\\\\n\"}', name='execute_python'), type='function')])\n",
            "\n",
            "Tool Used: execute_python\n",
            "Tool Input: {\"code\":\"import pandas as pd\\nimport matplotlib.pyplot as plt\\nimport seaborn as sns\\n\\n# 1) Read the data\\nfilepath = '/home/user/city_temperature.csv'\\ndf = pd.read_csv(filepath)\\n\\n# 2) Convert the AvgTemperature column to numeric if needed\\n#   (assuming it's already numeric in Celsius as stated, but just in case)\\ndf['AvgTemperature'] = pd.to_numeric(df['AvgTemperature'], errors='coerce')\\n\\n# Make sure no invalid entries\\ndf = df.dropna(subset=['AvgTemperature'])\\n\\n# 3) Find top 5 hottest cities by overall average temperature\\ncity_avg_temps = df.groupby('City', as_index=False)['AvgTemperature'].mean()\\ncity_avg_temps_sorted = city_avg_temps.sort_values('AvgTemperature', ascending=False)\\ntop_5_cities = city_avg_temps_sorted.head(5)['City'].tolist()\\n\\n# 4) Filter dataframe to include only top 5 cities\\nfiltered_df = df[df['City'].isin(top_5_cities)]\\n\\n# 5) Group by city and year to compute average temperature\\nyearly_mean = filtered_df.groupby(['City', 'Year'], as_index=False)['AvgTemperature'].mean()\\n\\n# 6) Create a line plot using seaborn or matplotlib\\nplt.figure(figsize=(10,6))\\nsns.lineplot(data=yearly_mean, x='Year', y='AvgTemperature', hue='City', marker='o')\\nplt.title('Yearly Average Temperatures for Top 5 Hottest Cities')\\nplt.xlabel('Year')\\nplt.ylabel('Average Temperature (C)')\\nplt.legend(title='City')\\nplt.tight_layout()\\nplt.show()\\n\"}\n",
            "Running code interpreter...\n",
            "Tool Result: [Result(<Figure size 1000x600 with 1 Axes>)]\n",
            "Result: Result(<Figure size 1000x600 with 1 Axes>)\n",
            "Success: Image generated and saved as temperature_analysis.png\n"
          ]
        }
      ],
      "source": [
        "import base64\n",
        "\n",
        "def main():\n",
        "    code_interpreter = Sandbox(api_key=E2B_API_KEY)\n",
        "    \n",
        "    try:\n",
        "        # First upload the dataset\n",
        "        remote_path = upload_dataset(code_interpreter)\n",
        "        print('Remote path of the uploaded dataset:', remote_path)\n",
        "        \n",
        "        # Then execute your analysis\n",
        "        code_interpreter_results = chat_with_llm(\n",
        "            code_interpreter,\n",
        "            'Analyze the temperature data for the top 5 hottest cities globally. Create a visualization showing their average temperatures over the years.'\n",
        "        )\n",
        "        \n",
        "        result = code_interpreter_results[0]\n",
        "        print('Result:', result)\n",
        "        if hasattr(result, 'png') and result.png:\n",
        "            with open('temperature_analysis.png', 'wb') as f:\n",
        "                f.write(base64.b64decode(result.png))\n",
        "            print('Success: Image generated and saved as temperature_analysis.png')\n",
        "        else:\n",
        "            print('Error: No PNG data available.')\n",
        "            \n",
        "    except Exception as error:\n",
        "        print('An error occurred:', error)\n",
        "        raise error\n",
        "    finally:\n",
        "        code_interpreter.kill()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
